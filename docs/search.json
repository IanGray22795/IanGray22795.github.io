[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a blog to show my work as a Data Scientist. I am a graduate from BYU-I with a Bachelor’s of Science in Data Science. I have been Working as a Data Analyst for 3 years at Dunlop Sports America providing technology and data expertise as the business grows and utilizes data as the driving force for automation and efficency in the company. Additionally, I have several years of extra experience working with different companies during my undergraduate to complete data projects such as pipelines and automated reporting using my skills and knowledge of SQL, Python, Power BI, R, and Tableau."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ian Gray Blog",
    "section": "",
    "text": "The Montny Hall Problem or 3 Door Problem\n\n\n\n\n\n\n\nPython\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2024\n\n\nIan Gray\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Outcomes\n\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nRCW Presentation\n\n\n\n\n\n\n\nPresentation\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nAWS s3 a New Way to Access Data\n\n\n\n\n\n\n\nAnalysis\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nDuckDB Synopses\n\n\n\n\n\n\n\nNews\n\n\nAnalysis\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\nIan Gray\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Dec_1st_presentation/index.html",
    "href": "posts/Dec_1st_presentation/index.html",
    "title": "RCW Presentation",
    "section": "",
    "text": "Here are some useful links and examples for a more indepth look into DuckDB."
  },
  {
    "objectID": "posts/Dec_1st_presentation/index.html#r",
    "href": "posts/Dec_1st_presentation/index.html#r",
    "title": "RCW Presentation",
    "section": "R",
    "text": "R\n\n\nbuilding_the_database.r\n\nlibrary(\"DBI\")\nlibrary(\"tidyverse\")\n\nMagic_DB = dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE)\n\ndbExecute(Magic_DB, \"CREATE SCHEMA IF NOT EXISTS MTG;\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Cards AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\cards.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Legalities AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\legalities.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Meta AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\meta.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Rulings AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\rulings.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Set_translations AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\set_translations.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Sets AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\sets.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Tokens AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\tokens.csv',SAMPLE_SIZE=-1);\")\n\ncon <- dbGetQuery(Magic_DB, \"SELECT * FROM MTG.Sets LIMIT 10\")\nView(con)\ncon_1 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Cards;\")\nView(con_1)\ncon_2 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Sets;\")\nView(con_2) \n\n\ncon_3 <- dbGetQuery(Magic_DB, \"SELECT s.code, c.rarity, s.name, c.name FROM MTG.Cards c JOIN MTG.Sets s ON c.setcode = s.code LIMIT 50\")\nView(con_3)\n\ndbDisconnect(Magic_DB, shutdown = TRUE)"
  },
  {
    "objectID": "posts/Dec_4th_Project_post/index.html",
    "href": "posts/Dec_4th_Project_post/index.html",
    "title": "Project Outcomes",
    "section": "",
    "text": "Project Deliverables/Goals\n\nConstruct a database using duckdb of the entire Magic the Gathering Card collection that is completely transferable from one system to another without conection to a main hub. | Completed \\(\\checkmark\\)\nImplment the Duckdb database using Python and R in tandem. | Completed \\(\\checkmark\\)\nExpand understanding of Duckdb to provide guidance on its uses and advantages when needing to use a database. | Completed \\(\\checkmark\\)\nProvide analytical review of magic the gathering cards using the constructed Duckdb database as the data source. | Incomlpete\n\n\nDatabase Implementation and Transferability\nUsing Duck_DB and it’s integrated packages to build databases in R and Python I was able to create a fully transferable database all held on github for anyone to download and analyze.\n\n\n\n\nflowchart LR\n  A(MTG_JSON:Data) --> B(Duck_DB:Database)\n  B(DUCK_DB:DATABASE) --> C[GITHUB Repository:Transferability]\n\n\n\n\n\n\n\nDuck_DB it’s Uses and Structure\nThis was a large part of my project studying the finest details of Duck_DB and how/ when it is best implemented and when it can be used to solve problems in other projects. AWS is one case where Duck_DB is exteremly useful for analyzing large aounts of data that is stored in an s3 bucket. Additionally, when there might be an issue with computer memory it is extermely useful for analyzing data. I found it very useful for another project where I was able to analyze millions of rows of data exteremly quickly and effieciently even though the size of the data was to large for R to handle in a single data frame."
  },
  {
    "objectID": "posts/Nov_17th/index.html",
    "href": "posts/Nov_17th/index.html",
    "title": "AWS s3 a New Way to Access Data",
    "section": "",
    "text": "Storage to be Accessed From Anywhere\nWith a proper internet access you can pull and manipulate data from s3 with just a simple key.\n\n\nWhat is s3?\nSimple, Storage, Service that is the expanded acronym for s3. In essence s3 or a s3 bucket is a simple storage provided as a service by cloud computing companies such as Amazon and Google. One of the most interesting things abour s3 is that it is a flat storage container although it looks very similar to your file system on your local computer. The one big difference is that when searching for files in s3 a program will see all files even if they are contained in a folder.\n\n\nHow is This Useful\nBeing a storage system that anyone with access can pull files from and uopload files to and have the same structure to read files into programs is valuable enough. It also is extremely cheap for business use as 1TB coud run you a maximum of $10 a month. The support for R and Python through packages that have been built is useful for data science and data analytics work.\n\n\nDuckDB and s3\nDuckDB has extensions, that will eventually be included in the base package, to connect directly to a s3 bucket. Just by setting the bucket name, pass key, and secret pass key if applicable you can pull all data from the s3 bucket to analyze and manipulate using duckdb.\n\n\ns3_start_up.py\n\n#first we build the the database\npip install duckdb==0.6.0\nimport duckdb as db\nDB = db.connect(database = \":memory:\", read_only = False)\n\n#note: as of this post the extension is non functional in R but works in python\nDB.execute(\"\"\"INSTALL httpfs;\n                 LOAD httpfs\"\"\")\n#set access variables\nDB.execute(\"\"\"SET s3_region = 'region of bucket';\n              SET s3_access_key_id = 'AWS access key id';\n              SET s3_secret_access_key = 'AWS secret access key';\"\"\")\n\nDB.execute(\"SELECT * FROM parquet_scan('s3:''bucket_name/*.parquetZ')\")\n\n\n\nArrow and s3\nAnother common way to interact with s3 is using the arrow package in R or Python. this is useful in R right now since duckdb extension crashes the r terminal. The Arrow package is also useful for other data wrangling features as well.\n\n\nusing_arrow.r\n\ninstall.packages(\"arrow\")\nlibrary(arrow)\n#this returns a dataframe of each object in the s3 bucket\nget_bucket_df(bucket = 's3://my-bucket/')\n#pulls data from s3 of a specific type an error will be thrown if there are files of different types in the s3 storage\nopen_dataset(source = 's3://my-bucket/', format = 'file type')"
  },
  {
    "objectID": "posts/Nov_7th/index.html",
    "href": "posts/Nov_7th/index.html",
    "title": "DuckDB Synopses",
    "section": "",
    "text": "What is DuckDB\nDuckDB is an online analytical processing (OLAP) Database Management System (DBMS) run in process.\n\n\nWhy Use DuckDB\nThere are several DBMS MySQL, PostgreSQL, SQLite to name a few. DuckDB is one that that has uses outside of what other DBMS can do or be used for. Referencing their page duckdb.org. Processing and storing tabular datasets is quick and easy to analyze, joining and aggregating large datasets is made simple through SQL queries, and doing large concurent changes to multiple tables quickly and efficiently.\n\n\nStarting With DuckDB\n\n\nStarting_with_duckdb.r\n\ninstall.packages(\"duckdb\")\nlibrary(duckdb)\n#Start your first database\nDB <- dbConnect(duckdb::duckdb(), dbir = \":memory:\") \n\nWe use the “:memory:” variable to save the data base as a non-physical file and hold the database in memory.\nThrough these simple lines of code we build a database to start inputing data into. This is easily done through sql insert statments or loading in R data frames or csv/parquet files as such.\n\n\nInputing_your_data.r\n\n#inputing data directly with SQL statments\ndbExecute(DB, \"\"\"CREATE TABLE a (id INTEGER, name VARCHAR);\n                 INSERT INTO a VALUES (1, bob), (2, kate), (3, drew);\"\"\") \n                 \n#taking an r dataframe and inputing it into the database\ndbWriteTable(DB, \"iris_table\", iris) \n\nIn the previous R snippet I showed how to create and table and put values into it in two of three ways duckdb suggests. Additionally, the way the SQL statement is coded to allow for multiple lines in a single function by using “;” to split Queries just like in normal SQL syntax.\n\n\nSimple Yet Powerful\nJust as shown above DuckDB is simple to use and easy to work with. additionally it encourages learning in multiple languages to get the best use from it. seeing as SQL, R, and Python are the best languages to learn for Data Science and Data Analytics it can be a powerful teaching tool. It also is best used for large data sources and can easily manipulate them with the dplyr as it natively convert dplyr functions into SQL Querys to analyza the data faster."
  },
  {
    "objectID": "posts/2024-12-7_3-doors/index.html",
    "href": "posts/2024-12-7_3-doors/index.html",
    "title": "The Montny Hall Problem or 3 Door Problem",
    "section": "",
    "text": "What Brought us here\nHave you ever gotten into an arguement before. My guess would be it was heated and potentially you didn’t like the person for some amount of time afterward. Well I can’t say that this arguement went the same way. it was actually pretty friendly. The only issue was neither of us were going to budge from our positions me and my wife of course. This arguement wasn’t of any import but was, for lack of a better term, Logic and statistically based. Meaning it was only caused because one or both sides couldn’t understand the logic or statisticall probabliitiy of the situation itself.\nWhat was it that brought this arguement on well it is talked about in media. People know it as “The Monty Hall problem” see this reference fro reference: \n\n\nThe problem"
  },
  {
    "objectID": "posts/2024-12-7_3-doors/index.html#r",
    "href": "posts/2024-12-7_3-doors/index.html#r",
    "title": "The 3 Door Problem",
    "section": "R",
    "text": "R\n\n\nbuilding_the_database.r\n\nlibrary(\"DBI\")\nlibrary(\"tidyverse\")\n\nMagic_DB = dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE)\n\ndbExecute(Magic_DB, \"CREATE SCHEMA IF NOT EXISTS MTG;\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Cards AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\cards.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Legalities AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\legalities.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Meta AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\meta.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Rulings AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\rulings.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Set_translations AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\set_translations.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Sets AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\sets.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Tokens AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\tokens.csv',SAMPLE_SIZE=-1);\")\n\ncon <- dbGetQuery(Magic_DB, \"SELECT * FROM MTG.Sets LIMIT 10\")\nView(con)\ncon_1 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Cards;\")\nView(con_1)\ncon_2 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Sets;\")\nView(con_2) \n\n\ncon_3 <- dbGetQuery(Magic_DB, \"SELECT s.code, c.rarity, s.name, c.name FROM MTG.Cards c JOIN MTG.Sets s ON c.setcode = s.code LIMIT 50\")\nView(con_3)\n\ndbDisconnect(Magic_DB, shutdown = TRUE)"
  }
]