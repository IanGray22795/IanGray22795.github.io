[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ian Gray Blog",
    "section": "",
    "text": "Presentation\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nNews\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\nIan Gray\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Dec_1st_presentation/index.html",
    "href": "posts/Dec_1st_presentation/index.html",
    "title": "RCW Presentation",
    "section": "",
    "text": "go here"
  },
  {
    "objectID": "posts/Nov_17th/index.html",
    "href": "posts/Nov_17th/index.html",
    "title": "AWS s3 a New Way to Access Data",
    "section": "",
    "text": "What is s3?\nSimple, Storage, Service that is the expanded acronym for s3. In essence s3 or a s3 bucket is a simple storage provided as a service by cloud computing companies such as Amazon and Google. One of the most interesting things abour s3 is that it is a flat storage container although it looks very similar to your file system on your local computer. The one big difference is that when searching for files in s3 a program will see all files even if they are contained in a folder.\n\n\nHow is This Useful\nBeing a storage system that anyone with access can pull files from and uopload files to and have the same structure to read files into programs is valuable enough. It also is extremely cheap for business use as 1TB coud run you a maximum of $10 a month. The support for R and Python through packages that have been built is useful for data science and data analytics work.\n\n\nDuckDB and s3\nDuckDB has extensions, that will eventually be included in the base package, to connect directly to a s3 bucket. Just by setting the bucket name, pass key, and secret pass key if applicable you can pull all data from the s3 bucket to analyze and manipulate using duckdb.\n\n\ns3_start_up.py\n\n#first we build the the database\npip install duckdb==0.6.0\nimport duckdb as db\nDB = db.connect(database = \":memory:\", read_only = False)\n\n#note: as of this post the extension is non functional in R but works in python\nDB.execute(\"\"\"INSTALL httpfs;\n                 LOAD httpfs\"\"\")\n#set access variables\nDB.execute(\"\"\"SET s3_region = 'region of bucket';\n              SET s3_access_key_id = 'AWS access key id';\n              SET s3_secret_access_key = 'AWS secret access key';\"\"\")\n\nDB.execute(\"SELECT * FROM parquet_scan('s3:''bucket_name/*.parquetZ')\")\n\n\n\nArrow and s3\nAnother common way to interact with s3 is using the arrow package in R or Python. this is useful in R right now since duckdb extension crashes the r terminal. The Arrow package is also useful for other data wrangling features as well.\n\n\nusing_arrow.r\n\ninstall.packages(\"arrow\")\nlibrary(arrow)\n#this returns a dataframe of each object in the s3 bucket\nget_bucket_df(bucket = 's3://my-bucket/')\n#pulls data from s3 of a specific type an error will be thrown if there are files of different types in the s3 storage\nopen_dataset(source = 's3://my-bucket/', format = 'file type')"
  },
  {
    "objectID": "posts/Nov_7th/index.html",
    "href": "posts/Nov_7th/index.html",
    "title": "DuckDB Synopses",
    "section": "",
    "text": "What is DuckDB\nDuckDB is an online analytical processing (OLAP) Database Management System (DBMS) run in process.\n\n\nWhy Use DuckDB\nThere are several DBMS MySQL, PostgreSQL, SQLite to name a few. DuckDB is one that that has uses outside of what other DBMS can do or be used for. Referencing their page duckdb.org. Processing and storing tabular datasets is quick and easy to analyze, joining and aggregating large datasets is made simple through SQL queries, and doing large concurent changes to multiple tables quickly and efficiently.\n\n\nStarting With DuckDB\n\n\nStarting_with_duckdb.r\n\ninstall.packages(\"duckdb\")\nlibrary(duckdb)\n#Start your first database\nDB <- dbConnect(duckdb::duckdb(), dbir = \":memory:\") \n\nWe use the “:memory:” variable to save the data base as a non-physical file and hold the database in memory.\nThrough these simple lines of code we build a database to start inputing data into. This is easily done through sql insert statments or loading in R data frames or csv/parquet files as such.\n\n\nInputing_your_data.r\n\n#inputing data directly with SQL statments\ndbExecute(DB, \"\"\"CREATE TABLE a (id INTEGER, name VARCHAR);\n                 INSERT INTO a VALUES (1, bob), (2, kate), (3, drew);\"\"\") \n                 \n#taking an r dataframe and inputing it into the database\ndbWriteTable(DB, \"iris_table\", iris) \n\nIn the previous R snippet I showed how to create and table and put values into it in two of three ways duckdb suggests. Additionally, the way the SQL statement is coded to allow for multiple lines in a single function by using “;” to split Queries just like in normal SQL syntax.\n\n\nSimple Yet Powerful\nJust as shown above DuckDB is simple to use and easy to work with. additionally it encourages learning in multiple languages to get the best use from it. seeing as SQL, R, and Python are the best languages to learn for Data Science and Data Analytics it can be a powerful teaching tool. It also is best used for large data sources and can easily manipulate them with the dplyr as it natively convert dplyr functions into SQL Querys to analyza the data faster."
  }
]