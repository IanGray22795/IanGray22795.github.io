[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a blog to show my work as a Data Scientist. I am a graduate from BYU-I with a Bachelor’s of Science in Data Science. I have been Working as a Data Analyst for 3 years at Dunlop Sports America providing technology and data expertise as the business grows and utilizes data as the driving force for automation and efficency in the company. Additionally, I have several years of extra experience working with different companies during my undergraduate to complete data projects such as pipelines and automated reporting using my skills and knowledge of SQL, Python, Power BI, R, and Tableau."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ian Gray Blog",
    "section": "",
    "text": "The Montny Hall Problem or 3 Door Problem\n\n\n\n\n\n\n\nPython\n\n\nProbability\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2024\n\n\nIan Gray\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Outcomes\n\n\n\n\n\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nRCW Presentation\n\n\n\n\n\n\n\nPresentation\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nAWS s3 a New Way to Access Data\n\n\n\n\n\n\n\nAnalysis\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2022\n\n\nIan Gray\n\n\n\n\n\n\n  \n\n\n\n\nDuckDB Synopses\n\n\n\n\n\n\n\nNews\n\n\nAnalysis\n\n\nProject\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\nIan Gray\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Dec_1st_presentation/index.html",
    "href": "posts/Dec_1st_presentation/index.html",
    "title": "RCW Presentation",
    "section": "",
    "text": "Here are some useful links and examples for a more indepth look into DuckDB."
  },
  {
    "objectID": "posts/Dec_1st_presentation/index.html#r",
    "href": "posts/Dec_1st_presentation/index.html#r",
    "title": "RCW Presentation",
    "section": "R",
    "text": "R\n\n\nbuilding_the_database.r\n\nlibrary(\"DBI\")\nlibrary(\"tidyverse\")\n\nMagic_DB = dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE)\n\ndbExecute(Magic_DB, \"CREATE SCHEMA IF NOT EXISTS MTG;\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Cards AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\cards.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Legalities AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\legalities.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Meta AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\meta.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Rulings AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\rulings.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Set_translations AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\set_translations.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Sets AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\sets.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Tokens AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\tokens.csv',SAMPLE_SIZE=-1);\")\n\ncon <- dbGetQuery(Magic_DB, \"SELECT * FROM MTG.Sets LIMIT 10\")\nView(con)\ncon_1 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Cards;\")\nView(con_1)\ncon_2 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Sets;\")\nView(con_2) \n\n\ncon_3 <- dbGetQuery(Magic_DB, \"SELECT s.code, c.rarity, s.name, c.name FROM MTG.Cards c JOIN MTG.Sets s ON c.setcode = s.code LIMIT 50\")\nView(con_3)\n\ndbDisconnect(Magic_DB, shutdown = TRUE)"
  },
  {
    "objectID": "posts/Dec_4th_Project_post/index.html",
    "href": "posts/Dec_4th_Project_post/index.html",
    "title": "Project Outcomes",
    "section": "",
    "text": "Project Deliverables/Goals\n\nConstruct a database using duckdb of the entire Magic the Gathering Card collection that is completely transferable from one system to another without conection to a main hub. | Completed \\(\\checkmark\\)\nImplment the Duckdb database using Python and R in tandem. | Completed \\(\\checkmark\\)\nExpand understanding of Duckdb to provide guidance on its uses and advantages when needing to use a database. | Completed \\(\\checkmark\\)\nProvide analytical review of magic the gathering cards using the constructed Duckdb database as the data source. | Incomlpete\n\n\nDatabase Implementation and Transferability\nUsing Duck_DB and it’s integrated packages to build databases in R and Python I was able to create a fully transferable database all held on github for anyone to download and analyze.\n\n\n\n\nflowchart LR\n  A(MTG_JSON:Data) --> B(Duck_DB:Database)\n  B(DUCK_DB:DATABASE) --> C[GITHUB Repository:Transferability]\n\n\n\n\n\n\n\nDuck_DB it’s Uses and Structure\nThis was a large part of my project studying the finest details of Duck_DB and how/ when it is best implemented and when it can be used to solve problems in other projects. AWS is one case where Duck_DB is exteremly useful for analyzing large aounts of data that is stored in an s3 bucket. Additionally, when there might be an issue with computer memory it is extermely useful for analyzing data. I found it very useful for another project where I was able to analyze millions of rows of data exteremly quickly and effieciently even though the size of the data was to large for R to handle in a single data frame."
  },
  {
    "objectID": "posts/Nov_17th/index.html",
    "href": "posts/Nov_17th/index.html",
    "title": "AWS s3 a New Way to Access Data",
    "section": "",
    "text": "Storage to be Accessed From Anywhere\nWith a proper internet access you can pull and manipulate data from s3 with just a simple key.\n\n\nWhat is s3?\nSimple, Storage, Service that is the expanded acronym for s3. In essence s3 or a s3 bucket is a simple storage provided as a service by cloud computing companies such as Amazon and Google. One of the most interesting things abour s3 is that it is a flat storage container although it looks very similar to your file system on your local computer. The one big difference is that when searching for files in s3 a program will see all files even if they are contained in a folder.\n\n\nHow is This Useful\nBeing a storage system that anyone with access can pull files from and uopload files to and have the same structure to read files into programs is valuable enough. It also is extremely cheap for business use as 1TB coud run you a maximum of $10 a month. The support for R and Python through packages that have been built is useful for data science and data analytics work.\n\n\nDuckDB and s3\nDuckDB has extensions, that will eventually be included in the base package, to connect directly to a s3 bucket. Just by setting the bucket name, pass key, and secret pass key if applicable you can pull all data from the s3 bucket to analyze and manipulate using duckdb.\n\n\ns3_start_up.py\n\n#first we build the the database\npip install duckdb==0.6.0\nimport duckdb as db\nDB = db.connect(database = \":memory:\", read_only = False)\n\n#note: as of this post the extension is non functional in R but works in python\nDB.execute(\"\"\"INSTALL httpfs;\n                 LOAD httpfs\"\"\")\n#set access variables\nDB.execute(\"\"\"SET s3_region = 'region of bucket';\n              SET s3_access_key_id = 'AWS access key id';\n              SET s3_secret_access_key = 'AWS secret access key';\"\"\")\n\nDB.execute(\"SELECT * FROM parquet_scan('s3:''bucket_name/*.parquetZ')\")\n\n\n\nArrow and s3\nAnother common way to interact with s3 is using the arrow package in R or Python. this is useful in R right now since duckdb extension crashes the r terminal. The Arrow package is also useful for other data wrangling features as well.\n\n\nusing_arrow.r\n\ninstall.packages(\"arrow\")\nlibrary(arrow)\n#this returns a dataframe of each object in the s3 bucket\nget_bucket_df(bucket = 's3://my-bucket/')\n#pulls data from s3 of a specific type an error will be thrown if there are files of different types in the s3 storage\nopen_dataset(source = 's3://my-bucket/', format = 'file type')"
  },
  {
    "objectID": "posts/Nov_7th/index.html",
    "href": "posts/Nov_7th/index.html",
    "title": "DuckDB Synopses",
    "section": "",
    "text": "What is DuckDB\nDuckDB is an online analytical processing (OLAP) Database Management System (DBMS) run in process.\n\n\nWhy Use DuckDB\nThere are several DBMS MySQL, PostgreSQL, SQLite to name a few. DuckDB is one that that has uses outside of what other DBMS can do or be used for. Referencing their page duckdb.org. Processing and storing tabular datasets is quick and easy to analyze, joining and aggregating large datasets is made simple through SQL queries, and doing large concurent changes to multiple tables quickly and efficiently.\n\n\nStarting With DuckDB\n\n\nStarting_with_duckdb.r\n\ninstall.packages(\"duckdb\")\nlibrary(duckdb)\n#Start your first database\nDB <- dbConnect(duckdb::duckdb(), dbir = \":memory:\") \n\nWe use the “:memory:” variable to save the data base as a non-physical file and hold the database in memory.\nThrough these simple lines of code we build a database to start inputing data into. This is easily done through sql insert statments or loading in R data frames or csv/parquet files as such.\n\n\nInputing_your_data.r\n\n#inputing data directly with SQL statments\ndbExecute(DB, \"\"\"CREATE TABLE a (id INTEGER, name VARCHAR);\n                 INSERT INTO a VALUES (1, bob), (2, kate), (3, drew);\"\"\") \n                 \n#taking an r dataframe and inputing it into the database\ndbWriteTable(DB, \"iris_table\", iris) \n\nIn the previous R snippet I showed how to create and table and put values into it in two of three ways duckdb suggests. Additionally, the way the SQL statement is coded to allow for multiple lines in a single function by using “;” to split Queries just like in normal SQL syntax.\n\n\nSimple Yet Powerful\nJust as shown above DuckDB is simple to use and easy to work with. additionally it encourages learning in multiple languages to get the best use from it. seeing as SQL, R, and Python are the best languages to learn for Data Science and Data Analytics it can be a powerful teaching tool. It also is best used for large data sources and can easily manipulate them with the dplyr as it natively convert dplyr functions into SQL Querys to analyza the data faster."
  },
  {
    "objectID": "posts/2024-12-7_3-doors/index.html",
    "href": "posts/2024-12-7_3-doors/index.html",
    "title": "The Montny Hall Problem or 3 Door Problem",
    "section": "",
    "text": "What Brought us here\nHave you ever gotten into an arguement before. My guess would be it was heated and potentially you didn’t like the person for some amount of time afterward. Well I can’t say that this arguement went the same way. it was actually pretty friendly. The only issue was neither of us were going to budge from our positions me and my wife of course. This arguement wasn’t of any import but was, for lack of a better term, Logic and statistically based. Meaning it was only caused because one or both sides couldn’t understand the logic or statistical probabliitiy of the situation itself.\nWhat was it that brought this arguement on well it is talked about in media. People know it as “The Monty Hall problem” see this reference for reference: \n\n\nThe Problem\nAs described in the video above you the participant are given the choice of 3 doors leaving you a 1 in 3 chance of choosing the correct door. Then the host shows you what is behind one of the two doors that is not the winner because he knows which door is the winner already. After the losing door is revealed the host posses the question “Would you like to keep the door you picked or would you like to switch?” This is where all of the confusion with the problem stems from. The question of to switch or not to switch is at it’s core a question about prbabilities and we know from the success of Las Vegas and the Lottery how much the average human understands about probabilities.\n\n\nExplanation and Solution\nBack to the topic at hand what makes this problem relate to probabilities so closely. Well given an equal chance to pick the correct door between 3 doors you have a 1 in 3 chance of choosing correctly or 1/3 which is equivalent to 33.33%. Now if you had the choice between 2 doors you have a 1 in 2 chance of choosing correctly or 1/2 which is equivalent to 50% which is greater than 33.33%. At a glance this is simple math is 50 > 33.33 this is true picking between 2 doors you will always have a higher chance of choosing the correct door. This is where the misunderstanding of how probabilites come into play though. The question we have to ask ourselves are we picking between 2 doors or are we still picking between 3 doors. Take this as an example, I ask you to stick your hand in a bag with 2 marbles of the same color and one of a different color the goal for you is to have the marble of a different color in your hand. After you take the first marble out I offer to trade your one marble for both marbles that are left in the bag. What would be your decision be keep the 1 or take the 2 obviously take the 2 right because you go from 1/3 to 2/3 or from 33.33% to 66.66%. This is the same situation for the doors once the wrong door is revealed it becomes innately attached to the last door in a group for your choosing. So you have the decision between two groups one with 2 doors and the other with one door. Which is why the odds are 33.33% if you stay with the same choice or 66.66% if you switch.\n\n\nDemonstration\n```{python}\nfrom random import randint\nimport pandas as pd\nimport itertools as ito\n\n# Function picks which door is correct\ndef correct_door():\n  return randint(0, 2)\n\n# Function creates a list of doors and assigns one as the correct door\ndef create_doors():\n  door = [0,0,0]\n  door[correct_door()] = 1\n  return door\n\n# Function generates a number to pick a door form \ndef pick_door():\n  pick = randint(0,2)\n  return pick\n\n# Function reveals the door left in the list that is incorrect\ndef remove_incorrect_door(doors):\n  if sum(doors) > 0:\n    doors.remove(0)\n  else:\n    doors.pop(randint(0,1))\n    return doors\n\n# Fucntion checks to see if switching the door was correct  \ndef always_switch_doors():\n  doors = create_doors()\n  pick = pick_door()\n  your_pick = doors.pop(pick)\n  remove_incorrect_door(doors)\n  if sum(doors) == 1:\n    return 1\n  else:\n    return 0\n\n# Function checks to see if keeping your door was correct \ndef never_switch_doors():\n  doors = create_doors()\n  pick = pick_door()\n  your_pick = doors.pop(pick)\n  if your_pick == 1:\n    return 1\n  else:\n    return 0\n  \n\n# writes a number of instances for previous functions and writes each instance to a data frame\ndef create_df(instances):\n  column1 = []\n  column2 = []\n  n=0\n  while n < instances:\n    column1.append(always_switch_doors())\n    column2.append(never_switch_doors())\n    n+=1\n  data = {\n    \"fun1\" : column1,\n    \"fun2\" : column2\n  }\n  data = pd.DataFrame(data)\n  return data\n\n# Runs and builds a data frame      \ndt = create_df(1000)\n\n# basic data exploration to understand outcomes\ndt.info()\n\nswitching = sum(dt[\"fun1\"])\nno_switch = sum(dt[\"fun2\"])\n\n# print(switching)\n# print(no_switch)\n```"
  },
  {
    "objectID": "posts/2024-12-7_3-doors/index.html#r",
    "href": "posts/2024-12-7_3-doors/index.html#r",
    "title": "The 3 Door Problem",
    "section": "R",
    "text": "R\n\n\nbuilding_the_database.r\n\nlibrary(\"DBI\")\nlibrary(\"tidyverse\")\n\nMagic_DB = dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE)\n\ndbExecute(Magic_DB, \"CREATE SCHEMA IF NOT EXISTS MTG;\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Cards AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\cards.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Legalities AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\legalities.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Meta AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\meta.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Rulings AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\rulings.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Set_translations AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\set_translations.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Sets AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\sets.csv',SAMPLE_SIZE=-1);\")\ndbExecute(Magic_DB, \"CREATE OR REPLACE TABLE MTG.Tokens AS SELECT * FROM read_csv_auto('..\\\\MTG_Database\\\\data\\\\sqllite_data\\\\AllPrintingsCSVFiles\\\\tokens.csv',SAMPLE_SIZE=-1);\")\n\ncon <- dbGetQuery(Magic_DB, \"SELECT * FROM MTG.Sets LIMIT 10\")\nView(con)\ncon_1 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Cards;\")\nView(con_1)\ncon_2 <- dbGetQuery(Magic_DB, \"DESCRIBE MTG.Sets;\")\nView(con_2) \n\n\ncon_3 <- dbGetQuery(Magic_DB, \"SELECT s.code, c.rarity, s.name, c.name FROM MTG.Cards c JOIN MTG.Sets s ON c.setcode = s.code LIMIT 50\")\nView(con_3)\n\ndbDisconnect(Magic_DB, shutdown = TRUE)"
  }
]